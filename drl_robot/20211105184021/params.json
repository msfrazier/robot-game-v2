{"learning_rate": [0.001], "layers": [[32, 32]], "activation": ["relu", "tanh", "sigmoid"], "mini_batch_size": [100], "memory_size": [1000], "reg_const": [0.0], "epsilon_decay": [0.99], "state_size": [6], "action_size": [10]}