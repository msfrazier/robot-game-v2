{"action_size": 10, "activation": "relu", "epsilon_decay": 0.99, "layers": [32, 32], "learning_rate": 0.001, "memory_size": 10000, "mini_batch_size": 1000, "momentum": 0.99, "reg_const": 0.0, "state_size": 6}