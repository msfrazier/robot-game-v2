{"action_size": 10, "activation": "relu", "epsilon_decay": 0.9, "layers": [256, 128, 64, 32], "memory_size": 10000, "mini_batch_size": 1000, "momentum": 0.99, "output_activation": "linear", "reg_const": 0.0, "state_size": [27]}